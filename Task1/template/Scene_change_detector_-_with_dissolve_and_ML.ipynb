{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интеллектуальные методы обработки видео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ноутбук разделен на два задания:\n",
    "   * ### [Эвристический SCD](#first)\n",
    "   * ### [SCD с ML](#second)\n",
    "   \n",
    "Сроки выполнения для каждого задания — одна неделя. Оцениваются задания независимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Scene Change Detector\n",
    "<a id='first'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательно к прочтению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!**\n",
    "\n",
    "Opencv содержит очень много высокоуровневых функций обработки изображений (например, некоторые алгоритмы компенсации движения, отслеживания объектов, распознавания образов). Использование данной библиотеки в данном задании ограничивается:\n",
    "* считыванием входного видео\n",
    "* преобразованием его кадров в другие цветовые пространства\n",
    "* использованием свёрток Собеля\n",
    "\n",
    "Использовать библиотеку numpy можно без ограничений.\n",
    "\n",
    "Если вы хотите использовать функции обработки изображений и видео из другой библиотеки, то оговорите использование этой функции в чате курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка для тренировки лежит https://titan.gml-team.ru:5003/sharing/yX8enupJV\n",
    "\n",
    "Данные о каждом видео лежат в файле *train_dataset\\info.json*. Это список из словарей, каждый словарь содержит информацию о расположении видео, о расположении ответов на смены сцен и содержит длину видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # Для установки opencv воспользуйтесь командой в терминале conda install -c conda-forge opencv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import notebook \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f, strict=False)\n",
    "\n",
    "\n",
    "def dump_json_to_file(obj, filename, **kwargs):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(obj, f, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'source': 'video/03.mp4', 'scene_change': 'gt/03.json', 'len': 3250},\n {'source': 'video/04.mp4', 'scene_change': 'gt/04.json', 'len': 3392},\n {'source': 'video/05.mp4', 'scene_change': 'gt/05.json', 'len': 5662},\n {'source': 'video/07.mp4', 'scene_change': 'gt/07.json', 'len': 3321},\n {'source': 'video/08.mp4', 'scene_change': 'gt/08.json', 'len': 3396},\n {'source': 'video/10.mp4', 'scene_change': 'gt/10.json', 'len': 6096},\n {'source': 'video/14.mp4', 'scene_change': 'gt/14.json', 'len': 2326},\n {'source': 'video/17.mp4', 'scene_change': 'gt/17.json', 'len': 2904},\n {'source': 'video/21.mp4', 'scene_change': 'gt/21.json', 'len': 4898},\n {'source': 'video/22.mp4', 'scene_change': 'gt/22.json', 'len': 7749}]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dataset = load_json_from_file('train_dataset/info.json')\n",
    "video_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка видео ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка видео осуществляется при помощи cv2.VideoCapture. Этот код изменять и дописывать не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        yield frame\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое frames? Это итератор на кадры видео. Чтобы пройтись по всем кадрам последовательности, воспользуйтесь следующей конструкцией:\n",
    "*Аккуратно, по одной переменной frames можно пройти только один раз!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for frame in tqdm(frames):\n",
    "    pass\n",
    "for frame in tqdm(frames): # Второй раз уже не будет итерации\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем свой простой детектор смен сцен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе предлагается написать простой Scene Change Detector (SCD) на основе выделения характеристик кадров, подсчёта разницы между кадрами на основе данных характеристик, а также подобрать наиболее оптимальный порог для этих признаков и совместить эти признаки.\n",
    "Сменой сцен в данной задаче являются только обычные мгновенные смены сцен, без дополнительных эффектов.\n",
    "\n",
    "В качестве примера приведён простой детектор смен, который считает межкадровую разницу между кадрами.\n",
    "\n",
    "*Важное замечание. Здесь и далее результатом алгоритма детектора сцен являются **индексы кадров начал сцен**, при этом кадры **нумеруются с 0**. Нулевой кадр в качестве ответа указывать не нужно*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Hard_cut.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def baseline_scene_change_detector(frames, threshold=2000, with_vis=False):\n",
    "    \"\"\"\n",
    "    Baseline SCD\n",
    "\n",
    "    Arguments:\n",
    "    frames -- iterator on video frames\n",
    "    threshold -- parameter of your algorithm (optional)\n",
    "    with_vis -- saving neighboring frames at a scene change (optional)\n",
    "\n",
    "    Returns:\n",
    "    scene_changes -- list of scene changes (idx of frames)\n",
    "    vis -- list of neighboring frames at a scene change (for visualization)\n",
    "    metric_values -- list of metric values (for visualization)\n",
    "    \"\"\"\n",
    "    \n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        # Базовое расстояние между кадрами - среднеквадратическая ошибка между ними\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    prev_frame = None\n",
    "    for idx, frame in notebook.tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        if prev_frame is not None:\n",
    "            # Находим расстояние между соседними кадрами\n",
    "            metric_value = pixel_metric(frame, prev_frame)\n",
    "            metric_values.append({'metric_value' : metric_value})\n",
    "        else:\n",
    "            metric_values.append({'metric_value' : 0})\n",
    "        prev_frame = frame\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "cuts_base = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['cut']\n",
    "scene_changes_base, vis_base, metric_values_base = baseline_scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим визуально, насколько сильно алгоритм ошибается, а также на значения метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_error(frame, prev_frame, value):\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    plt.suptitle('Значение метрики на текущем кадре: {:.4f}'.format(value), fontsize=24)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(prev_frame[:,:,::-1])\n",
    "    ax.set_title(\"Предыдущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(frame[:,:,::-1])\n",
    "    ax.set_title(\"Текущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.subplots_adjust(top=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 10\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# ошибается, это не смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_values(metric_values, threshold, cuts = None):\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(metric_values, label='Значение метрики на кадрах')\n",
    "    plt.xlabel('Номер кадра')\n",
    "    plt.ylabel('Значение метрики')\n",
    "    plt.hlines(y=threshold, xmin=0, xmax=len(metric_values), linewidth=2, color='r', label='Пороговое значение')\n",
    "    \n",
    "    if cuts is not None:\n",
    "        for cut in cuts:\n",
    "            plt.axvline(x=cut, color='k', linestyle=':', linewidth=0.5, label='Смена сцены')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_metric_values(metric_values_base, 2000, cuts_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как видим, очень плохо подобран порог, да и сам признак, похоже, сильно зашумлён. Попробуйте что-то своё!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector\n",
    "\n",
    "def scene_change_detector(frames, threshold=None, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    hist_metric_values = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "\n",
    "    mask = None\n",
    "\n",
    "    prev_frame = None\n",
    "    prev_frame_hist = None\n",
    "    hist_size = 16\n",
    "    frames_seq_len = 9\n",
    "    metrics_weight = 1.15\n",
    "    hist_weight = 1.3\n",
    "    hard_metrics_threshold = 11000\n",
    "\n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "    def hist_metric(frame_hist,prev_frame_hist):\n",
    "        return np.mean((frame_hist - prev_frame_hist) ** 2)\n",
    "    def hist(frame):\n",
    "        return cv2.calcHist(frame,[0], mask, [hist_size], [0, 256])\n",
    "\n",
    "    ###  END CODE HERE  ###\n",
    "\n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        if mask is not None:\n",
    "            mask = np.zeros(frame[0].shape[:2], np.uint8)\n",
    "            height, width, _ = frame.shape\n",
    "            mask[(height // 5):(4 * height // 5), (width // 5):(4 * width // 5)] = 255\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        pass\n",
    "        # Основная часть вашего алгоритма\n",
    "        frame_hist = hist(frame)\n",
    "        if prev_frame is not None:\n",
    "            metric_value = pixel_metric(frame, prev_frame)\n",
    "            hist_metric_value = hist_metric(frame_hist, prev_frame_hist)\n",
    "            metric_values.append({'metric_value' : metric_value})\n",
    "            hist_metric_values.append(hist_metric_value)\n",
    "\n",
    "            if idx > frames_seq_len:\n",
    "                mean = np.mean(metric_values[-frames_seq_len:])\n",
    "                hist_mean = np.mean(hist_metric_values[-frames_seq_len:])\n",
    "                if (metric_values[idx - ((frames_seq_len + 1) // 2) + 1] / mean * metrics_weight + hist_metric_values[idx - ((frames_seq_len + 1) // 2) + 1] / hist_mean * hist_weight) > 13.0:\n",
    "                    scene_changes.append(idx - ((frames_seq_len + 1) // 2) + 1)\n",
    "        else:\n",
    "            metric_values.append({'metric_value' : 0.0})\n",
    "            hist_metric_values.append(0)\n",
    "        prev_frame = frame\n",
    "        prev_frame_hist = frame_hist\n",
    "\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doodo\\AppData\\Local\\Temp\\ipykernel_14676\\2875675897.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, frame in tqdm(enumerate(frames), leave=False):\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f69f7a00db4d4e9309c43cb0581749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m frames \u001B[38;5;241m=\u001B[39m read_video(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_dataset\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvideo\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m03.mp4\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m      2\u001B[0m cuts \u001B[38;5;241m=\u001B[39m load_json_from_file(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_dataset\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m03.json\u001B[39m\u001B[38;5;124m'\u001B[39m))[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcut\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m----> 3\u001B[0m scene_changes, vis, metric_values \u001B[38;5;241m=\u001B[39m \u001B[43mscene_change_detector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwith_vis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[41], line 44\u001B[0m, in \u001B[0;36mscene_change_detector\u001B[1;34m(frames, threshold, with_vis)\u001B[0m\n\u001B[0;32m     42\u001B[0m frame_hist \u001B[38;5;241m=\u001B[39m hist(frame)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prev_frame \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 44\u001B[0m     metric_value \u001B[38;5;241m=\u001B[39m \u001B[43mpixel_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprev_frame\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m     hist_metric_value \u001B[38;5;241m=\u001B[39m hist_metric(frame_hist, prev_frame_hist)\n\u001B[0;32m     46\u001B[0m     metric_values\u001B[38;5;241m.\u001B[39mappend(metric_value)\n",
      "Cell \u001B[1;32mIn[41], line 23\u001B[0m, in \u001B[0;36mscene_change_detector.<locals>.pixel_metric\u001B[1;34m(frame, prev_frame)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpixel_metric\u001B[39m(frame, prev_frame):\n\u001B[1;32m---> 23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean((\u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint32\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m prev_frame) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "cuts = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['cut']\n",
    "scene_changes, vis, metric_values = scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обратите внимание на скорость работы алгоритма! ####\n",
    "Если вычислять признаки без циклов по пикселям, а пользоваться методами из numpy, то скорость будет не медленнее 7-8 кадров в секунду.\n",
    "Например, вы можете использовать функцию `np.histogram` или `cv2.calcHist` для подсчёта гистограмм, а `cv2.Sobel` для применения оператора Собеля к кадру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Посмотрим на найденные смены сцен\n",
    "idx = 1 \n",
    "visualize_metric_error(vis[idx][0], vis[idx][1], metric_values[scene_changes[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на значения метрики\n",
    "visualize_metric_values(metric_values, 2000, cuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчёт метрики F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценивать алгоритм и научиться сравнивать несколько алгоритмов, нужна метрика качества. В данной задаче для оценки качества алгоритма используется F1-Score. Преимущества использования этой метрики к текущей постановке задачи смены сцен были рассказаны на лекции, напишем только формулы:\n",
    "$$precision = \\frac{tp}{tp+fp}$$\n",
    "$$recall = \\frac{tp}{tp+fn}$$\n",
    "$$F = 2 * \\frac{precision * recall}{precision+recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай опишем как именно происходит подсчёт метрики для видео\n",
    "\n",
    "1) Сначала из выборки удаляются все кадры, которые по разметке либо являются сложными переходами между сценами, либо помечены как сложные для анализа и разметки (например, титры/обилие компьютерной графики и т.п)\n",
    "\n",
    "\n",
    "2) Затем для оставшихся кадров уже подсчитывается F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти пять клеток кода править не нужно\n",
    "def calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    for scd in predicted_scd:\n",
    "        if scd in true_scd:\n",
    "            tp += 1\n",
    "        elif scd not in not_to_use_frames:\n",
    "            fp += 1\n",
    "    for scd in true_scd:\n",
    "        if scd not in predicted_scd:\n",
    "            fn += 1\n",
    "    tn = scene_len - len(not_to_use_frames) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_precision(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_recall(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_matrix(tp, fp, tn, fn):\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем разработанный метод сразу на нескольких видео "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, насколько хорошо работает разработанный метод. *Учтите, что итоговое тестирование будет производиться на аналогичном, но недоступном вам наборе видео, но все параметры алгоритмов должны быть указаны вами (иными словами - подобраны на тренировочном наборе).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        # Загружаем видео, его длину и смены сцен\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        # Составляем список сцен, которые не будут тестироваться\n",
    "        not_use_frames = set()\n",
    "        for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "            for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "                not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        \n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        \n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn \n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset = 'train_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция поможет вам посмотреть, на каких видео и на сколько ошибается ваш метод. Прогнать метод на отдельном видео и детально посмотреть кадры вы могли выше.\n",
    "\n",
    "Кроме того, с помощью этой функции вы можете подобрать оптимальные параметры для метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем базовый метод\n",
    "run_scene_change_detector_all_video(baseline_scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doodo\\AppData\\Local\\Temp\\ipykernel_14676\\4126358636.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for video_info in tqdm(video_dataset, leave=False):\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9ca1e293024f65a40dfbb23247686b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doodo\\AppData\\Local\\Temp\\ipykernel_14676\\3384297497.py:31: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, frame in tqdm(enumerate(frames), leave=False):\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f1a5a75ab64aab8d066f3eb47a1d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video(scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы смотрите на результат, обращайте внимание на **_mean_f1_score**  \n",
    "Именно по этой метрике будет производится финальное оценивание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: распознавание смен сцен типа \"наложения\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике кроме катов часто встречаются смены сцен, где происходит \"наложение\" одной сцены на другую:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dissolve.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector_dissolve(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_dissolve\n",
    "\n",
    "def scene_change_detector_dissolve(frames, threshold=None, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        pass\n",
    "        # Основная часть вашего алгоритма\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества используется видоизменённый f1-score:\n",
    "\n",
    "Так как смена сцен не происходит за один кадр, попаданием считается попадание ответа смены сцен в отрезок, где происходит наложение.  \n",
    "**Обратите внимание**, что несколько раз указывать одну смену сцен не нужно.\n",
    "\n",
    "Попадание вне отрезков смен сцен путём наложения считается как false positive, не попадание в указанный отрезок - как false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти три клетки кода править не нужно\n",
    "def calculate_matrix_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    checked_dissolve_segments = set()\n",
    "    total_scene_dissolve_len = np.sum([dissolve_segment[1] - dissolve_segment[0] + 1 for dissolve_segment in true_scd])\n",
    "    for scd in predicted_scd:\n",
    "        for dissolve_segment in true_scd:\n",
    "            if scd in range(dissolve_segment[0], dissolve_segment[1] + 1):\n",
    "                tp += 1\n",
    "                checked_dissolve_segments.add(tuple(dissolve_segment))\n",
    "                break\n",
    "        else:\n",
    "            fp += 1\n",
    "    fn = len(true_scd) - len(checked_dissolve_segments)\n",
    "    tn = scene_len - total_scene_dissolve_len + len(true_scd) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    tp, fp, tn, fn = calculate_matrix_dissolve(true_scd, predicted_scd, scene_len)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video_dissolve(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn\n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video_dissolve(scene_change_detector_dissolve, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немного об оценивании задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценивание задания будет производиться по следующей схеме:  \n",
    "\n",
    "Пусть на скрытой выборке по F-метрике вы получили X, лучшее решение получило Y.\n",
    "\n",
    "1. Базовая часть оценивется как $$20 * \\left(\\frac{\\max(0, X_{base} - 0.5)}{Y_{base} - 0.5}\\right)^2 + Bonus_{base}$$ Бонусные баллы $Bonus$ можно получить за оригинальные идеи в задаче или в её реализации\n",
    "2. Дополнительное задание оценивается как $$5 * \\frac{\\max(0, X_{add} - 0.1)}{Y_{add} - 0.1} + Bonus_{add}$$Процесс получения бонусных баллов аналогичен получению бонусных баллов в базовой части"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваши ощущения ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*До дедлайна пару часов и вы никак не можете улучшить текущее решение? Или наоборот, вы всё сделали очень быстро? Опишите кратко ваши ощущения от задания - сколько времени вы потратили на задание, сколько вы потратили на изучение питона и установку необходимых библиотек, как быстро вы придумывали новые идеи и как они давали прирост по метрике и в целом насколько это задание вам понравилось и что хотели бы изменить/добавить.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='second'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Scene change detector. Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!**\n",
    "\n",
    "В этом задании можно использовать все, что разрешалось в Задании №1, а также библиотеки:\n",
    "* pandas\n",
    "* sklearn\n",
    "\n",
    "Большинство функций, использующихся в этом задании, реализованы выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим простой SVM классификатор над метрикой попиксельной разницы кадров на нескольких видео. Воспользуемся функцией из первого задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(train_videos):\n",
    "    X_train, y_train = pd.DataFrame(), np.array([])\n",
    "    for video in train_videos:\n",
    "        frames = read_video(os.path.join('train_dataset', 'video', f'{video}.mp4'))\n",
    "        # baseline функция попиксельного сравнения кадров из прошлого задания\n",
    "        # нам нужны не сами смены сцен, а только значения метрик\n",
    "        _, _, metric_values = baseline_scene_change_detector(frames) \n",
    "        \n",
    "        cuts = load_json_from_file(os.path.join('train_dataset', 'gt', f'{video}.json'))['cut']\n",
    "        video_scenes = np.array([0 for i in range(len(metric_values))])\n",
    "        video_scenes[cuts] += 1\n",
    "        \n",
    "        # добавляем в разметку текущее видео\n",
    "        X_train = X_train.append(metric_values)\n",
    "        y_train = np.hstack((y_train, video_scenes))\n",
    "        \n",
    "    return X_train, y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d34fbf52b874d9badbd4000058ccdda"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.006352663040161133,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doodo\\AppData\\Local\\Temp\\ipykernel_13920\\1715947297.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train = X_train.append(metric_values)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f2948e7106040d2ac8eccdd4fb5fc40"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.007012367248535156,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doodo\\AppData\\Local\\Temp\\ipykernel_13920\\1715947297.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train = X_train.append(metric_values)\n"
     ]
    }
   ],
   "source": [
    "train_videos = ['04', '05']\n",
    "\n",
    "X_train, y_train = get_train_data(train_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(C=1)",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создание модели\n",
    "# подберите лучшие параметры для данной задачи\n",
    "params = {\"kernel\": \"rbf\", \"C\": 1}\n",
    "model = SVC(**params)\n",
    "model.fit(pd.DataFrame(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Сохраним модель в файле *model.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как модель работает на тестовых видео\n",
    "\n",
    "Обратите внимание на то, что внутри функции модель загружается из памяти из файла *model.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_scene_change_detection_ml(frames):\n",
    "    # подготавливаем данные для видео\n",
    "    _, _, metric_values = baseline_scene_change_detector(frames) \n",
    "    X_test = pd.DataFrame(metric_values)\n",
    "    \n",
    "    # загружаем модель и делаем предсказания\n",
    "    model = pickle.load(open(\"model.pkl\", 'rb'))\n",
    "    predict_cuts = model.predict(X_test)\n",
    "    \n",
    "    return np.where(predict_cuts > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scene_change_detector_ml_one_video(scene_change_detector, dataset_path, video_num):\n",
    "    video_info = load_json_from_file(os.path.join(dataset_path, 'info.json'))[video_num]\n",
    "    \n",
    "    # Загружаем видео, его длину и смены сцен\n",
    "    frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "    video_len = video_info['len']\n",
    "    true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "\n",
    "    # Составляем список сцен, которые не будут тестироваться\n",
    "    not_use_frames = set()\n",
    "    for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "        for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "            not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "\n",
    "    predicted_scene_changes = scene_change_detector(frames)\n",
    "\n",
    "    return  f1_score(\n",
    "        true_scene_changes['cut'],\n",
    "        predicted_scene_changes,\n",
    "        video_len,\n",
    "        not_use_frames\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем F1 score для одного видео:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a108e57b5d034e2897ef1288fe566045"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.007214784622192383,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.8317757009345794"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_num = 3\n",
    "run_scene_change_detector_ml_one_video(baseline_scene_change_detection_ml, 'train_dataset', video_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 144,  170,  213,  273,  277,  278,  280,  281,  282,  284,  289,\n        291,  292,  293,  294,  295,  296,  297,  298,  299,  300,  301,\n        307,  308,  309,  313,  315,  355,  399,  427,  490,  529,  578,\n        610,  651,  682,  739,  818,  837,  857,  880,  949,  975, 1024,\n       1056, 1092, 1136, 1171, 1189, 1209, 1230, 1305, 1374, 1390, 1447,\n       1480, 1500, 1515, 1533, 1547, 1576, 1604, 1622, 1664, 1686, 1703,\n       1728, 1742, 1763, 1785, 1862, 1889, 1917, 1950, 1970, 1996, 2018,\n       2052, 2070, 2077, 2101, 2129, 2178, 2191, 2193, 2202, 2241, 2283,\n       2324, 2349, 2371, 2403, 2438, 2461, 2488, 2555, 2582, 2644, 2664,\n       2712, 2751, 2786, 2851, 2870, 2883, 2899, 2912, 2954, 2991, 3020,\n       3136, 3216], dtype=int64)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_scene_changes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted_scene_changes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать свою обученную модель при отправке решения, необходимо сохранить ее через пакет pickle в файл model.pkl и отправить его вместе с jupyter ноутбуком.\n",
    "Этот файл вы можете открывать и использовать прямо в функции вашего решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector_dissolve(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_ml\n",
    "\n",
    "def scene_change_detector_ml(frames, with_vis = False):\n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        return np.nanmean((frame[:,:,0].astype(np.int32) - prev_frame[:,:,0]) ** 2)\n",
    "    def hist_metric(frame_hist,prev_frame_hist):\n",
    "        return np.nanmean(abs(frame_hist - prev_frame_hist))\n",
    "    def hist(frame, mask, hist_size):\n",
    "        return cv2.calcHist([frame],[0], mask, [hist_size], [0, 256])\n",
    "    def sobel(frame):\n",
    "        return np.where(cv2.Sobel(frame[:,:,0],cv2.CV_8U,1,0) + cv2.Sobel(frame[:,:,0],cv2.CV_8U,0,1) > 250, 1, 0)\n",
    "    def sobel_metric(frame_sobel, prev_frame_sobel):\n",
    "        return np.nanmean((frame_sobel - prev_frame_sobel) ** 2)\n",
    "    def br_mean(frame):\n",
    "        return np.mean(frame[:,:,0])\n",
    "    def metric_generator(frames):\n",
    "        metrics = []\n",
    "        metric_values = []\n",
    "        hist_metric_values = []\n",
    "        hist_metric_values_1q = []\n",
    "        hist_metric_values_2q = []\n",
    "        hist_metric_values_3q = []\n",
    "        hist_metric_values_4q = []\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Ваши внешние переменные\n",
    "\n",
    "        mask = None\n",
    "        mask_1q = None\n",
    "        mask_2q = None\n",
    "        mask_3q = None\n",
    "        mask_4q = None\n",
    "\n",
    "        prev_frame = None\n",
    "        prev_frame_hist = None\n",
    "        prev_frame_1q_hist = None\n",
    "        prev_frame_2q_hist = None\n",
    "        prev_frame_3q_hist = None\n",
    "        prev_frame_4q_hist = None\n",
    "        prev_frame_sobel = None\n",
    "\n",
    "        hist_size = 256\n",
    "        frames_seq_len = 7\n",
    "\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "        for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "            # frame - это кадр\n",
    "            # idx - это номер кадра\n",
    "            mean = float(0)\n",
    "            hist_mean = float(0)\n",
    "            frame_features = {}\n",
    "            if mask is None:\n",
    "                height, width, _ = frame.shape\n",
    "                mask = np.zeros((height, width), np.uint8)\n",
    "                mask[(2 * height // 7):(5 * height // 7), (2 * width // 7):(5 * width // 7)] = 255\n",
    "\n",
    "                mask_1q = frame[0 : height // 2, 0 : width // 2]\n",
    "                mask_2q = frame[0 : height // 2, width // 2 : width]\n",
    "                mask_3q = frame[height // 2 : height, 0 : width // 2]\n",
    "                mask_4q = frame[height // 2 : height, width // 2 : width]\n",
    "\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "            frame_features['br_mean'] = br_mean(frame)\n",
    "            frame_hist = hist(frame, mask, hist_size)\n",
    "            frame_sobel = sobel(frame)\n",
    "\n",
    "            frame_1q_hist = hist(mask_1q, None, hist_size)\n",
    "            frame_2q_hist = hist(mask_2q, None, hist_size)\n",
    "            frame_3q_hist = hist(mask_3q, None, hist_size)\n",
    "            frame_4q_hist = hist(mask_4q, None, hist_size)\n",
    "\n",
    "            if prev_frame is not None:\n",
    "                frame_features['br_mean_prev'] = br_mean(prev_frame)\n",
    "                metric_value = pixel_metric(frame, prev_frame)\n",
    "                hist_metric_value = hist_metric(frame_hist, prev_frame_hist)\n",
    "                #sobel_metric_value = sobel_metric(frame_sobel, prev_frame_sobel)\n",
    "                metric_values.append(metric_value)\n",
    "                hist_metric_values.append(hist_metric_value)\n",
    "                frame_features['metric_value'] = metric_value\n",
    "                #frame_features['sobel_metric_value'] = sobel_metric_value\n",
    "\n",
    "                hist_metric_value_1q = hist_metric(frame_1q_hist, prev_frame_1q_hist)\n",
    "                hist_metric_value_2q = hist_metric(frame_1q_hist, prev_frame_2q_hist)\n",
    "                hist_metric_value_3q = hist_metric(frame_1q_hist, prev_frame_3q_hist)\n",
    "                hist_metric_value_4q = hist_metric(frame_4q_hist, prev_frame_4q_hist)\n",
    "\n",
    "                hist_metric_values_1q.append(hist_metric_value_1q)\n",
    "                hist_metric_values_2q.append(hist_metric_value_2q)\n",
    "                hist_metric_values_3q.append(hist_metric_value_3q)\n",
    "                hist_metric_values_4q.append(hist_metric_value_4q)\n",
    "\n",
    "                frame_features['hist_metric_value'] =  hist_metric_value\n",
    "                frame_features['hist_metric_value_1q'] =  hist_metric_value_1q\n",
    "                frame_features['hist_metric_value_2q'] =  hist_metric_value_2q\n",
    "                frame_features['hist_metric_value_3q'] =  hist_metric_value_3q\n",
    "                frame_features['hist_metric_value_4q'] =  hist_metric_value_4q\n",
    "\n",
    "                if idx >= frames_seq_len - 1:\n",
    "                    mean = float(np.nanmean(metric_values[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + metric_values[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean = float(np.nanmean(hist_metric_values[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['mean'] = mean\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean'] = hist_mean\n",
    "\n",
    "                    hist_mean_1q = float(np.nanmean(hist_metric_values_1q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_1q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean_2q = float(np.nanmean(hist_metric_values_2q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_2q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean_3q = float(np.nanmean(hist_metric_values_3q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_3q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean_4q = float(np.nanmean(hist_metric_values_4q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_4q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_1q'] = hist_mean_1q\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_2q'] = hist_mean_2q\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_3q'] = hist_mean_3q\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_4q'] = hist_mean_4q\n",
    "\n",
    "                elif idx == frames_seq_len - 2:\n",
    "                    for i in range(0, (frames_seq_len) // 2):\n",
    "                        mean = float(np.nanmean(metric_values[0: i] + metric_values[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        metrics[i]['mean'] = mean\n",
    "                        hist_mean = float(np.nanmean(hist_metric_values[0: i] + hist_metric_values[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        metrics[i]['hist_mean'] = hist_mean\n",
    "\n",
    "                        hist_mean_1q = float(np.nanmean(hist_metric_values_1q[0: i] + hist_metric_values_1q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        hist_mean_2q = float(np.nanmean(hist_metric_values_2q[0: i] + hist_metric_values_2q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        hist_mean_3q = float(np.nanmean(hist_metric_values_3q[0: i] + hist_metric_values_3q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        hist_mean_4q = float(np.nanmean(hist_metric_values_4q[0: i] + hist_metric_values_4q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "\n",
    "                        metrics[i]['hist_mean_1q'] = hist_mean_1q\n",
    "                        metrics[i]['hist_mean_2q'] = hist_mean_2q\n",
    "                        metrics[i]['hist_mean_3q'] = hist_mean_3q\n",
    "                        metrics[i]['hist_mean_4q'] = hist_mean_4q\n",
    "\n",
    "            else:\n",
    "                frame_features['br_mean_prev'] = 0\n",
    "\n",
    "                frame_features['metric_value'] = 0\n",
    "                metric_values.append(0)\n",
    "                frame_features['hist_metric_value'] = 0\n",
    "                hist_metric_values.append(0)\n",
    "                #frame_features['sobel_metric_value'] = 0\n",
    "\n",
    "                frame_features['hist_metric_value_1q'] =  0\n",
    "                frame_features['hist_metric_value_2q'] =  0\n",
    "                frame_features['hist_metric_value_3q'] =  0\n",
    "                frame_features['hist_metric_value_4q'] =  0\n",
    "\n",
    "                hist_metric_values_1q.append(0)\n",
    "                hist_metric_values_2q.append(0)\n",
    "                hist_metric_values_3q.append(0)\n",
    "                hist_metric_values_4q.append(0)\n",
    "\n",
    "            prev_frame = frame\n",
    "            prev_frame_hist = frame_hist\n",
    "            prev_frame_sobel = frame_sobel\n",
    "\n",
    "            prev_frame_1q_hist = frame_1q_hist\n",
    "            prev_frame_2q_hist = frame_2q_hist\n",
    "            prev_frame_3q_hist = frame_3q_hist\n",
    "            prev_frame_4q_hist = frame_4q_hist\n",
    "\n",
    "            metrics.append(frame_features)\n",
    "            ###  END CODE HERE  ###\n",
    "        for i in range(len(metric_values) - (frames_seq_len) // 2, len(metric_values)):\n",
    "            mean = float(np.nanmean(metric_values[i - (frames_seq_len) // 2 : i] + metric_values[i + 1 : len(metric_values)]))\n",
    "            metrics[i]['mean'] = mean\n",
    "            hist_mean = float(np.nanmean(hist_metric_values[i - (frames_seq_len) // 2 : i] + hist_metric_values[i + 1 : len(metric_values)]))\n",
    "            metrics[i]['hist_mean'] = hist_mean\n",
    "\n",
    "            hist_mean_1q = float(np.nanmean(hist_metric_values_1q[i - (frames_seq_len) // 2 : i] + hist_metric_values_1q[i + 1 : len(metric_values)]))\n",
    "            hist_mean_2q = float(np.nanmean(hist_metric_values_2q[i - (frames_seq_len) // 2 : i] + hist_metric_values_2q[i + 1 : len(metric_values)]))\n",
    "            hist_mean_3q = float(np.nanmean(hist_metric_values_3q[i - (frames_seq_len) // 2 : i] + hist_metric_values_3q[i + 1 : len(metric_values)]))\n",
    "            hist_mean_4q = float(np.nanmean(hist_metric_values_4q[i - (frames_seq_len) // 2 : i] + hist_metric_values_4q[i + 1 : len(metric_values)]))\n",
    "\n",
    "            metrics[i]['hist_mean_1q'] = hist_mean_1q\n",
    "            metrics[i]['hist_mean_2q'] = hist_mean_2q\n",
    "            metrics[i]['hist_mean_3q'] = hist_mean_3q\n",
    "            metrics[i]['hist_mean_4q'] = hist_mean_4q\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    X_test = pd.DataFrame(metric_generator(frames))\n",
    "    model = pickle.load(open(\"model.pkl\", 'rb'))\n",
    "    predict_cuts = model.predict(X_test)\n",
    "\n",
    "    return np.where(predict_cuts == 1)[0], None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим ваше решение на всех видео.\n",
    "\n",
    "Не забывайте о том, что при итоговой оценке решений будет использоваться другой набор видео. Не переобучите модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scene_change_detector_all_video(scene_change_detector_ml, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Советы**\n",
    "\n",
    "* Используйте кросс-валидацию\n",
    "* Подумайте как лучше разделять видео на тренировочную и тестовые выборки\n",
    "* Подбирайте параметры модели (в библиотеке sklearn есть метод GridSearchCV для автоматического подбора параметров)\n",
    "* Пробуйте разные методы машинного обучения (из sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: детектор смен сцен типа наложение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично детектору из задания №1 за исключением того, что можно (и нужно) использовать машинное обучение:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_dissolve_ml\n",
    "\n",
    "def scene_change_detector_dissolve_ml(frames, threshold=None, with_vis=False):\n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        return np.nanmean((frame[:,:,0].astype(np.int32) - prev_frame[:,:,0]) ** 2)\n",
    "    def hist_metric(frame_hist,prev_frame_hist):\n",
    "        return np.nanmean(abs(frame_hist - prev_frame_hist))\n",
    "    def hist(frame, mask, hist_size):\n",
    "        return cv2.calcHist([frame],[0], mask, [hist_size], [0, 256])\n",
    "    def sobel(frame):\n",
    "        return np.where(cv2.Sobel(frame[:,:,0],cv2.CV_8U,1,0) + cv2.Sobel(frame[:,:,0],cv2.CV_8U,0,1) > 250, 1, 0)\n",
    "    def sobel_metric(frame_sobel, prev_frame_sobel):\n",
    "        return np.nanmean((frame_sobel - prev_frame_sobel) ** 2)\n",
    "    def br_mean(frame):\n",
    "        return np.mean(frame[:,:,0])\n",
    "    def metric_generator(frames):\n",
    "        metrics = []\n",
    "        metric_values = []\n",
    "        hist_metric_values = []\n",
    "        hist_metric_values_1q = []\n",
    "        hist_metric_values_2q = []\n",
    "        hist_metric_values_3q = []\n",
    "        hist_metric_values_4q = []\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Ваши внешние переменные\n",
    "\n",
    "        mask = None\n",
    "        mask_1q = None\n",
    "        mask_2q = None\n",
    "        mask_3q = None\n",
    "        mask_4q = None\n",
    "\n",
    "        prev_frame = None\n",
    "        prev_frame_hist = None\n",
    "        prev_frame_1q_hist = None\n",
    "        prev_frame_2q_hist = None\n",
    "        prev_frame_3q_hist = None\n",
    "        prev_frame_4q_hist = None\n",
    "        prev_frame_sobel = None\n",
    "\n",
    "        hist_size = 256\n",
    "        frames_seq_len = 7\n",
    "\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "        for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "            # frame - это кадр\n",
    "            # idx - это номер кадра\n",
    "            mean = float(0)\n",
    "            hist_mean = float(0)\n",
    "            frame_features = {}\n",
    "            if mask is None:\n",
    "                height, width, _ = frame.shape\n",
    "                mask = np.zeros((height, width), np.uint8)\n",
    "                mask[(2 * height // 7):(5 * height // 7), (2 * width // 7):(5 * width // 7)] = 255\n",
    "\n",
    "                mask_1q = frame[0 : height // 2, 0 : width // 2]\n",
    "                mask_2q = frame[0 : height // 2, width // 2 : width]\n",
    "                mask_3q = frame[height // 2 : height, 0 : width // 2]\n",
    "                mask_4q = frame[height // 2 : height, width // 2 : width]\n",
    "\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "            frame_features['br_mean'] = br_mean(frame)\n",
    "            frame_hist = hist(frame, mask, hist_size)\n",
    "            frame_sobel = sobel(frame)\n",
    "\n",
    "            frame_1q_hist = hist(mask_1q, None, hist_size)\n",
    "            frame_2q_hist = hist(mask_2q, None, hist_size)\n",
    "            frame_3q_hist = hist(mask_3q, None, hist_size)\n",
    "            frame_4q_hist = hist(mask_4q, None, hist_size)\n",
    "\n",
    "            if prev_frame is not None:\n",
    "                frame_features['br_mean_prev'] = br_mean(prev_frame)\n",
    "                metric_value = pixel_metric(frame, prev_frame)\n",
    "                hist_metric_value = hist_metric(frame_hist, prev_frame_hist)\n",
    "                #sobel_metric_value = sobel_metric(frame_sobel, prev_frame_sobel)\n",
    "                metric_values.append(metric_value)\n",
    "                hist_metric_values.append(hist_metric_value)\n",
    "                frame_features['metric_value'] = metric_value\n",
    "                #frame_features['sobel_metric_value'] = sobel_metric_value\n",
    "\n",
    "                hist_metric_value_1q = hist_metric(frame_1q_hist, prev_frame_1q_hist)\n",
    "                hist_metric_value_2q = hist_metric(frame_1q_hist, prev_frame_2q_hist)\n",
    "                hist_metric_value_3q = hist_metric(frame_1q_hist, prev_frame_3q_hist)\n",
    "                hist_metric_value_4q = hist_metric(frame_4q_hist, prev_frame_4q_hist)\n",
    "\n",
    "                hist_metric_values_1q.append(hist_metric_value_1q)\n",
    "                hist_metric_values_2q.append(hist_metric_value_2q)\n",
    "                hist_metric_values_3q.append(hist_metric_value_3q)\n",
    "                hist_metric_values_4q.append(hist_metric_value_4q)\n",
    "\n",
    "                frame_features['hist_metric_value'] =  hist_metric_value\n",
    "                frame_features['hist_metric_value_1q'] =  hist_metric_value_1q\n",
    "                frame_features['hist_metric_value_2q'] =  hist_metric_value_2q\n",
    "                frame_features['hist_metric_value_3q'] =  hist_metric_value_3q\n",
    "                frame_features['hist_metric_value_4q'] =  hist_metric_value_4q\n",
    "\n",
    "                if idx >= frames_seq_len - 1:\n",
    "                    mean = float(np.nanmean(metric_values[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + metric_values[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean = float(np.nanmean(hist_metric_values[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['mean'] = mean\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean'] = hist_mean\n",
    "\n",
    "                    hist_mean_1q = float(np.nanmean(hist_metric_values_1q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_1q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean_2q = float(np.nanmean(hist_metric_values_2q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_2q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean_3q = float(np.nanmean(hist_metric_values_3q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_3q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "                    hist_mean_4q = float(np.nanmean(hist_metric_values_4q[-frames_seq_len: idx - ((frames_seq_len + 1) // 2) + 1] + hist_metric_values_4q[idx - ((frames_seq_len + 1) // 2) + 2:]))\n",
    "\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_1q'] = hist_mean_1q\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_2q'] = hist_mean_2q\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_3q'] = hist_mean_3q\n",
    "                    metrics[idx - ((frames_seq_len + 1) // 2) + 1]['hist_mean_4q'] = hist_mean_4q\n",
    "\n",
    "                elif idx == frames_seq_len - 2:\n",
    "                    for i in range(0, (frames_seq_len) // 2):\n",
    "                        mean = float(np.nanmean(metric_values[0: i] + metric_values[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        metrics[i]['mean'] = mean\n",
    "                        hist_mean = float(np.nanmean(hist_metric_values[0: i] + hist_metric_values[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        metrics[i]['hist_mean'] = hist_mean\n",
    "\n",
    "                        hist_mean_1q = float(np.nanmean(hist_metric_values_1q[0: i] + hist_metric_values_1q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        hist_mean_2q = float(np.nanmean(hist_metric_values_2q[0: i] + hist_metric_values_2q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        hist_mean_3q = float(np.nanmean(hist_metric_values_3q[0: i] + hist_metric_values_3q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "                        hist_mean_4q = float(np.nanmean(hist_metric_values_4q[0: i] + hist_metric_values_4q[i + 1 : (frames_seq_len)// 2 + i + 1]))\n",
    "\n",
    "                        metrics[i]['hist_mean_1q'] = hist_mean_1q\n",
    "                        metrics[i]['hist_mean_2q'] = hist_mean_2q\n",
    "                        metrics[i]['hist_mean_3q'] = hist_mean_3q\n",
    "                        metrics[i]['hist_mean_4q'] = hist_mean_4q\n",
    "\n",
    "            else:\n",
    "                frame_features['br_mean_prev'] = 0\n",
    "\n",
    "                frame_features['metric_value'] = 0\n",
    "                metric_values.append(0)\n",
    "                frame_features['hist_metric_value'] = 0\n",
    "                hist_metric_values.append(0)\n",
    "                #frame_features['sobel_metric_value'] = 0\n",
    "\n",
    "                frame_features['hist_metric_value_1q'] =  0\n",
    "                frame_features['hist_metric_value_2q'] =  0\n",
    "                frame_features['hist_metric_value_3q'] =  0\n",
    "                frame_features['hist_metric_value_4q'] =  0\n",
    "\n",
    "                hist_metric_values_1q.append(0)\n",
    "                hist_metric_values_2q.append(0)\n",
    "                hist_metric_values_3q.append(0)\n",
    "                hist_metric_values_4q.append(0)\n",
    "\n",
    "            prev_frame = frame\n",
    "            prev_frame_hist = frame_hist\n",
    "            prev_frame_sobel = frame_sobel\n",
    "\n",
    "            prev_frame_1q_hist = frame_1q_hist\n",
    "            prev_frame_2q_hist = frame_2q_hist\n",
    "            prev_frame_3q_hist = frame_3q_hist\n",
    "            prev_frame_4q_hist = frame_4q_hist\n",
    "\n",
    "            metrics.append(frame_features)\n",
    "            ###  END CODE HERE  ###\n",
    "        for i in range(len(metric_values) - (frames_seq_len) // 2, len(metric_values)):\n",
    "            mean = float(np.nanmean(metric_values[i - (frames_seq_len) // 2 : i] + metric_values[i + 1 : len(metric_values)]))\n",
    "            metrics[i]['mean'] = mean\n",
    "            hist_mean = float(np.nanmean(hist_metric_values[i - (frames_seq_len) // 2 : i] + hist_metric_values[i + 1 : len(metric_values)]))\n",
    "            metrics[i]['hist_mean'] = hist_mean\n",
    "\n",
    "            hist_mean_1q = float(np.nanmean(hist_metric_values_1q[i - (frames_seq_len) // 2 : i] + hist_metric_values_1q[i + 1 : len(metric_values)]))\n",
    "            hist_mean_2q = float(np.nanmean(hist_metric_values_2q[i - (frames_seq_len) // 2 : i] + hist_metric_values_2q[i + 1 : len(metric_values)]))\n",
    "            hist_mean_3q = float(np.nanmean(hist_metric_values_3q[i - (frames_seq_len) // 2 : i] + hist_metric_values_3q[i + 1 : len(metric_values)]))\n",
    "            hist_mean_4q = float(np.nanmean(hist_metric_values_4q[i - (frames_seq_len) // 2 : i] + hist_metric_values_4q[i + 1 : len(metric_values)]))\n",
    "\n",
    "            metrics[i]['hist_mean_1q'] = hist_mean_1q\n",
    "            metrics[i]['hist_mean_2q'] = hist_mean_2q\n",
    "            metrics[i]['hist_mean_3q'] = hist_mean_3q\n",
    "            metrics[i]['hist_mean_4q'] = hist_mean_4q\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    X_test = pd.DataFrame(metric_generator(frames))\n",
    "    model = pickle.load(open(\"model.pkl\", 'rb'))\n",
    "    predict_cuts = model.predict(X_test)\n",
    "\n",
    "    return np.where(predict_cuts == 1)[0], None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'\n",
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video_dissolve(scene_change_detector_dissolve, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваши ощущения ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как и в первой части интересно узнать какие моменты показались простыми, а какие сложными. Много ли времени ушло на изучение sklearn и методов машинного обучения. Дало ли машинное обучение сразу прирост по сравнению с эврестической частью? Как вы контролировали переобучение?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
