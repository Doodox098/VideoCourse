{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интеллектуальные методы обработки видео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ноутбук разделен на два задания:\n",
    "   * ### [Эвристический SCD](#first)\n",
    "   * ### [SCD с ML](#second)\n",
    "   \n",
    "Сроки выполнения для каждого задания — одна неделя. Оцениваются задания независимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Scene Change Detector\n",
    "<a id='first'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательно к прочтению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!**\n",
    "\n",
    "Opencv содержит очень много высокоуровневых функций обработки изображений (например, некоторые алгоритмы компенсации движения, отслеживания объектов, распознавания образов). Использование данной библиотеки в данном задании ограничивается:\n",
    "* считыванием входного видео\n",
    "* преобразованием его кадров в другие цветовые пространства\n",
    "* использованием свёрток Собеля\n",
    "\n",
    "Использовать библиотеку numpy можно без ограничений.\n",
    "\n",
    "Если вы хотите использовать функции обработки изображений и видео из другой библиотеки, то оговорите использование этой функции в чате курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка для тренировки лежит https://titan.gml-team.ru:5003/sharing/yX8enupJV\n",
    "\n",
    "Данные о каждом видео лежат в файле *train_dataset\\info.json*. Это список из словарей, каждый словарь содержит информацию о расположении видео, о расположении ответов на смены сцен и содержит длину видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # Для установки opencv воспользуйтесь командой в терминале conda install -c conda-forge opencv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import notebook \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f, strict=False)\n",
    "\n",
    "\n",
    "def dump_json_to_file(obj, filename, **kwargs):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(obj, f, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'video/03.mp4', 'scene_change': 'gt/03.json', 'len': 3250},\n",
       " {'source': 'video/04.mp4', 'scene_change': 'gt/04.json', 'len': 3392},\n",
       " {'source': 'video/05.mp4', 'scene_change': 'gt/05.json', 'len': 5662},\n",
       " {'source': 'video/07.mp4', 'scene_change': 'gt/07.json', 'len': 3321},\n",
       " {'source': 'video/08.mp4', 'scene_change': 'gt/08.json', 'len': 3396},\n",
       " {'source': 'video/10.mp4', 'scene_change': 'gt/10.json', 'len': 6096},\n",
       " {'source': 'video/14.mp4', 'scene_change': 'gt/14.json', 'len': 2326},\n",
       " {'source': 'video/17.mp4', 'scene_change': 'gt/17.json', 'len': 2904},\n",
       " {'source': 'video/21.mp4', 'scene_change': 'gt/21.json', 'len': 4898},\n",
       " {'source': 'video/22.mp4', 'scene_change': 'gt/22.json', 'len': 7749}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dataset = load_json_from_file('train_dataset/info.json')\n",
    "video_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка видео ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка видео осуществляется при помощи cv2.VideoCapture. Этот код изменять и дописывать не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        yield frame\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое frames? Это итератор на кадры видео. Чтобы пройтись по всем кадрам последовательности, воспользуйтесь следующей конструкцией:\n",
    "*Аккуратно, по одной переменной frames можно пройти только один раз!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doodo\\AppData\\Local\\Temp\\ipykernel_4484\\4167052049.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for frame in tqdm(frames):\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m tqdm(frames): \u001b[38;5;66;03m# Второй раз уже не будет итерации\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\__init__.py:28\u001b[0m, in \u001b[0;36mtqdm_notebook\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m _tqdm_notebook\n\u001b[0;32m     25\u001b[0m warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function will be removed in tqdm==5.0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m      TqdmDeprecationWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tqdm_notebook(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py:240\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    239\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_here:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py:117\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIProgress not found. Please update jupyter and ipywidgets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m See https://ipywidgets.readthedocs.io/en/stable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/user_install.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    122\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "for frame in tqdm(frames):\n",
    "    pass\n",
    "for frame in tqdm(frames): # Второй раз уже не будет итерации\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем свой простой детектор смен сцен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе предлагается написать простой Scene Change Detector (SCD) на основе выделения характеристик кадров, подсчёта разницы между кадрами на основе данных характеристик, а также подобрать наиболее оптимальный порог для этих признаков и совместить эти признаки.\n",
    "Сменой сцен в данной задаче являются только обычные мгновенные смены сцен, без дополнительных эффектов.\n",
    "\n",
    "В качестве примера приведён простой детектор смен, который считает межкадровую разницу между кадрами.\n",
    "\n",
    "*Важное замечание. Здесь и далее результатом алгоритма детектора сцен являются **индексы кадров начал сцен**, при этом кадры **нумеруются с 0**. Нулевой кадр в качестве ответа указывать не нужно*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Hard_cut.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def baseline_scene_change_detector(frames, threshold=2000, with_vis=False):\n",
    "    \"\"\"\n",
    "    Baseline SCD\n",
    "\n",
    "    Arguments:\n",
    "    frames -- iterator on video frames\n",
    "    threshold -- parameter of your algorithm (optional)\n",
    "    with_vis -- saving neighboring frames at a scene change (optional)\n",
    "\n",
    "    Returns:\n",
    "    scene_changes -- list of scene changes (idx of frames)\n",
    "    vis -- list of neighboring frames at a scene change (for visualization)\n",
    "    metric_values -- list of metric values (for visualization)\n",
    "    \"\"\"\n",
    "    \n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        # Базовое расстояние между кадрами - среднеквадратическая ошибка между ними\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    prev_frame = None\n",
    "    for idx, frame in notebook.tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        if prev_frame is not None:\n",
    "            # Находим расстояние между соседними кадрами\n",
    "            metric_value = pixel_metric(frame, prev_frame)\n",
    "            if metric_value > threshold:\n",
    "                scene_changes.append(idx)\n",
    "                if with_vis:\n",
    "                    # Кадры в памяти занимают много места, поэтому сохраним лишь первые 100 срабатываний\n",
    "                    if len(vis) < 100:\n",
    "                        vis.append([prev_frame, frame])\n",
    "            metric_values.append(metric_value)\n",
    "        else:\n",
    "            metric_values.append(0)\n",
    "        prev_frame = frame\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007533073425292969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "cuts_base = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['cut']\n",
    "scene_changes_base, vis_base, metric_values_base = baseline_scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим визуально, насколько сильно алгоритм ошибается, а также на значения метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_error(frame, prev_frame, value):\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    plt.suptitle('Значение метрики на текущем кадре: {:.4f}'.format(value), fontsize=24)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(prev_frame[:,:,::-1])\n",
    "    ax.set_title(\"Предыдущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(frame[:,:,::-1])\n",
    "    ax.set_title(\"Текущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.subplots_adjust(top=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vis_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 2\u001b[0m visualize_metric_error(\u001b[43mvis_base\u001b[49m[idx][\u001b[38;5;241m0\u001b[39m], vis_base[idx][\u001b[38;5;241m1\u001b[39m], metric_values_base[scene_changes_base[idx]])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# смена сцен\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vis_base' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vis_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 2\u001b[0m visualize_metric_error(\u001b[43mvis_base\u001b[49m[idx][\u001b[38;5;241m0\u001b[39m], vis_base[idx][\u001b[38;5;241m1\u001b[39m], metric_values_base[scene_changes_base[idx]])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ошибается, это не смена сцен\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vis_base' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# ошибается, это не смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_values(metric_values, threshold, cuts = None):\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(metric_values, label='Значение метрики на кадрах')\n",
    "    plt.xlabel('Номер кадра')\n",
    "    plt.ylabel('Значение метрики')\n",
    "    plt.hlines(y=threshold, xmin=0, xmax=len(metric_values), linewidth=2, color='r', label='Пороговое значение')\n",
    "    \n",
    "    if cuts is not None:\n",
    "        for cut in cuts:\n",
    "            plt.axvline(x=cut, color='k', linestyle=':', linewidth=0.5, label='Смена сцены')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metric_values_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m visualize_metric_values(\u001b[43mmetric_values_base\u001b[49m, \u001b[38;5;241m2000\u001b[39m, cuts_base)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metric_values_base' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_metric_values(metric_values_base, 2000, cuts_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как видим, очень плохо подобран порог, да и сам признак, похоже, сильно зашумлён. Попробуйте что-то своё!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector\n",
    "\n",
    "def scene_change_detector(frames, threshold=None, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        pass\n",
    "        # Основная часть вашего алгоритма\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doodo\\AppData\\Local\\Temp\\ipykernel_4484\\1643560128.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx, frame in tqdm(enumerate(frames), leave=False):\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m frames \u001b[38;5;241m=\u001b[39m read_video(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m03.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m cuts \u001b[38;5;241m=\u001b[39m load_json_from_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m03.json\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcut\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m scene_changes, vis, metric_values \u001b[38;5;241m=\u001b[39m \u001b[43mscene_change_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_vis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m, in \u001b[0;36mscene_change_detector\u001b[1;34m(frames, threshold, with_vis)\u001b[0m\n\u001b[0;32m      6\u001b[0m metric_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m### START CODE HERE ###\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Ваши внешние переменные\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m###  END CODE HERE  ###\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, frame \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# frame - это кадр\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# idx - это номер кадра\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m### START CODE HERE ###\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Основная часть вашего алгоритма\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m###  END CODE HERE  ###\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\__init__.py:28\u001b[0m, in \u001b[0;36mtqdm_notebook\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m _tqdm_notebook\n\u001b[0;32m     25\u001b[0m warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function will be removed in tqdm==5.0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m      TqdmDeprecationWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tqdm_notebook(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py:240\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    239\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_here:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py:117\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIProgress not found. Please update jupyter and ipywidgets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m See https://ipywidgets.readthedocs.io/en/stable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/user_install.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    122\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "cuts = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['cut']\n",
    "scene_changes, vis, metric_values = scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обратите внимание на скорость работы алгоритма! ####\n",
    "Если вычислять признаки без циклов по пикселям, а пользоваться методами из numpy, то скорость будет не медленнее 7-8 кадров в секунду.\n",
    "Например, вы можете использовать функцию `np.histogram` или `cv2.calcHist` для подсчёта гистограмм, а `cv2.Sobel` для применения оператора Собеля к кадру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x0000021FD2EBE9E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\doodo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py\", line 1138, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\doodo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py\", line 285, in close\n",
      "    self.disp(close=True)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Посмотрим на найденные смены сцен\u001b[39;00m\n\u001b[0;32m      2\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m----> 3\u001b[0m visualize_metric_error(\u001b[43mvis\u001b[49m[idx][\u001b[38;5;241m0\u001b[39m], vis[idx][\u001b[38;5;241m1\u001b[39m], metric_values[scene_changes[idx]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vis' is not defined"
     ]
    }
   ],
   "source": [
    "#Посмотрим на найденные смены сцен\n",
    "idx = 1 \n",
    "visualize_metric_error(vis[idx][0], vis[idx][1], metric_values[scene_changes[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metric_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Посмотрим на значения метрики\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m visualize_metric_values(\u001b[43mmetric_values\u001b[49m, \u001b[38;5;241m2000\u001b[39m, cuts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metric_values' is not defined"
     ]
    }
   ],
   "source": [
    "#Посмотрим на значения метрики\n",
    "visualize_metric_values(metric_values, 2000, cuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчёт метрики F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценивать алгоритм и научиться сравнивать несколько алгоритмов, нужна метрика качества. В данной задаче для оценки качества алгоритма используется F1-Score. Преимущества использования этой метрики к текущей постановке задачи смены сцен были рассказаны на лекции, напишем только формулы:\n",
    "$$precision = \\frac{tp}{tp+fp}$$\n",
    "$$recall = \\frac{tp}{tp+fn}$$\n",
    "$$F = 2 * \\frac{precision * recall}{precision+recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай опишем как именно происходит подсчёт метрики для видео\n",
    "\n",
    "1) Сначала из выборки удаляются все кадры, которые по разметке либо являются сложными переходами между сценами, либо помечены как сложные для анализа и разметки (например, титры/обилие компьютерной графики и т.п)\n",
    "\n",
    "\n",
    "2) Затем для оставшихся кадров уже подсчитывается F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти пять клеток кода править не нужно\n",
    "def calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    for scd in predicted_scd:\n",
    "        if scd in true_scd:\n",
    "            tp += 1\n",
    "        elif scd not in not_to_use_frames:\n",
    "            fp += 1\n",
    "    for scd in true_scd:\n",
    "        if scd not in predicted_scd:\n",
    "            fn += 1\n",
    "    tn = scene_len - len(not_to_use_frames) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_precision(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_recall(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_matrix(tp, fp, tn, fn):\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем разработанный метод сразу на нескольких видео "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, насколько хорошо работает разработанный метод. *Учтите, что итоговое тестирование будет производиться на аналогичном, но недоступном вам наборе видео, но все параметры алгоритмов должны быть указаны вами (иными словами - подобраны на тренировочном наборе).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        # Загружаем видео, его длину и смены сцен\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        # Составляем список сцен, которые не будут тестироваться\n",
    "        not_use_frames = set()\n",
    "        for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "            for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "                not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        \n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        \n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn \n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset = 'train_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция поможет вам посмотреть, на каких видео и на сколько ошибается ваш метод. Прогнать метод на отдельном видео и детально посмотреть кадры вы могли выше.\n",
    "\n",
    "Кроме того, с помощью этой функции вы можете подобрать оптимальные параметры для метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем базовый метод\n",
    "run_scene_change_detector_all_video(baseline_scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video(scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы смотрите на результат, обращайте внимание на **_mean_f1_score**  \n",
    "Именно по этой метрике будет производится финальное оценивание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: распознавание смен сцен типа \"наложения\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике кроме катов часто встречаются смены сцен, где происходит \"наложение\" одной сцены на другую:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dissolve.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector_dissolve(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_dissolve\n",
    "\n",
    "def scene_change_detector_dissolve(frames, threshold=None, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        pass\n",
    "        # Основная часть вашего алгоритма\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества используется видоизменённый f1-score:\n",
    "\n",
    "Так как смена сцен не происходит за один кадр, попаданием считается попадание ответа смены сцен в отрезок, где происходит наложение.  \n",
    "**Обратите внимание**, что несколько раз указывать одну смену сцен не нужно.\n",
    "\n",
    "Попадание вне отрезков смен сцен путём наложения считается как false positive, не попадание в указанный отрезок - как false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти три клетки кода править не нужно\n",
    "def calculate_matrix_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    checked_dissolve_segments = set()\n",
    "    total_scene_dissolve_len = np.sum([dissolve_segment[1] - dissolve_segment[0] + 1 for dissolve_segment in true_scd])\n",
    "    for scd in predicted_scd:\n",
    "        for dissolve_segment in true_scd:\n",
    "            if scd in range(dissolve_segment[0], dissolve_segment[1] + 1):\n",
    "                tp += 1\n",
    "                checked_dissolve_segments.add(tuple(dissolve_segment))\n",
    "                break\n",
    "        else:\n",
    "            fp += 1\n",
    "    fn = len(true_scd) - len(checked_dissolve_segments)\n",
    "    tn = scene_len - total_scene_dissolve_len + len(true_scd) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    tp, fp, tn, fn = calculate_matrix_dissolve(true_scd, predicted_scd, scene_len)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video_dissolve(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn\n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video_dissolve(scene_change_detector_dissolve, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Немного об оценивании задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценивание задания будет производиться по следующей схеме:  \n",
    "\n",
    "Пусть на скрытой выборке по F-метрике вы получили X, лучшее решение получило Y.\n",
    "\n",
    "1. Базовая часть оценивется как $$20 * \\left(\\frac{\\max(0, X_{base} - 0.5)}{Y_{base} - 0.5}\\right)^2 + Bonus_{base}$$ Бонусные баллы $Bonus$ можно получить за оригинальные идеи в задаче или в её реализации\n",
    "2. Дополнительное задание оценивается как $$5 * \\frac{\\max(0, X_{add} - 0.1)}{Y_{add} - 0.1} + Bonus_{add}$$Процесс получения бонусных баллов аналогичен получению бонусных баллов в базовой части"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваши ощущения ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*До дедлайна пару часов и вы никак не можете улучшить текущее решение? Или наоборот, вы всё сделали очень быстро? Опишите кратко ваши ощущения от задания - сколько времени вы потратили на задание, сколько вы потратили на изучение питона и установку необходимых библиотек, как быстро вы придумывали новые идеи и как они давали прирост по метрике и в целом насколько это задание вам понравилось и что хотели бы изменить/добавить.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='second'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Scene change detector. Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!**\n",
    "\n",
    "В этом задании можно использовать все, что разрешалось в Задании №1, а также библиотеки:\n",
    "* pandas\n",
    "* sklearn\n",
    "\n",
    "Большинство функций, использующихся в этом задании, реализованы выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим простой SVM классификатор над метрикой попиксельной разницы кадров на нескольких видео. Воспользуемся функцией из первого задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(train_videos):\n",
    "    X_train, y_train = np.array([]), np.array([])\n",
    "    for video in train_videos:\n",
    "        frames = read_video(os.path.join('train_dataset', 'video', f'{video}.mp4'))\n",
    "        # baseline функция попиксельного сравнения кадров из прошлого задания\n",
    "        # нам нужны не сами смены сцен, а только значения метрик\n",
    "        _, _, metric_values = baseline_scene_change_detector(frames) \n",
    "        \n",
    "        cuts = load_json_from_file(os.path.join('train_dataset', 'gt', f'{video}.json'))['cut']\n",
    "        video_scenes = np.array([0 for i in range(len(metric_values))])\n",
    "        video_scenes[cuts] += 1\n",
    "        \n",
    "        # добавляем в разметку текущее видео\n",
    "        X_train = np.hstack((X_train, metric_values))\n",
    "        y_train = np.hstack((y_train, video_scenes))\n",
    "        \n",
    "    return X_train, y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_videos \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m04\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m05\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mget_trained_model\u001b[49m(train_videos)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_trained_model' is not defined"
     ]
    }
   ],
   "source": [
    "train_videos = ['04', '05']\n",
    "\n",
    "X_train, y_train = get_trained_model(train_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели\n",
    "# подберите лучшие параметры для данной задачи\n",
    "params = {\"kernel\": \"rbf\", \"C\": 1}\n",
    "model = SVC(**params)\n",
    "model.fit(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Сохраним модель в файле *model.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как модель работает на тестовых видео\n",
    "\n",
    "Обратите внимание на то, что внутри функции модель загружается из памяти из файла *model.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_scene_change_detection_ml(frames):\n",
    "    # подготавливаем данные для видео\n",
    "    _, _, metric_values = baseline_scene_change_detector(frames) \n",
    "    X_test = np.array(metric_values).reshape(-1, 1)\n",
    "    \n",
    "    # загружаем модель и делаем предсказания\n",
    "    model = pickle.load(open(\"model.pkl\", 'rb')) \n",
    "    predict_cuts = model.predict(X_test)\n",
    "    \n",
    "    return np.where(predict_cuts > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scene_change_detector_ml_one_video(scene_change_detector, dataset_path, video_num):\n",
    "    video_info = load_json_from_file(os.path.join(dataset_path, 'info.json'))[video_num]\n",
    "    \n",
    "    # Загружаем видео, его длину и смены сцен\n",
    "    frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "    video_len = video_info['len']\n",
    "    true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "\n",
    "    # Составляем список сцен, которые не будут тестироваться\n",
    "    not_use_frames = set()\n",
    "    for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "        for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "            not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "\n",
    "    predicted_scene_changes = scene_change_detector(frames)\n",
    "\n",
    "    return  f1_score(\n",
    "        true_scene_changes['cut'],\n",
    "        predicted_scene_changes,\n",
    "        video_len,\n",
    "        not_use_frames\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем F1 score для одного видео:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_num = 3\n",
    "run_scene_change_detector_ml_one_video(baseline_scene_change_detection_ml, 'train_dataset', video_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать свою обученную модель при отправке решения, необходимо сохранить ее через пакет pickle в файл model.pkl и отправить его вместе с jupyter ноутбуком.\n",
    "Этот файл вы можете открывать и использовать прямо в функции вашего решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector_dissolve(frames)`  \n",
    "* Строку (# GRADED CELL: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_ml\n",
    "\n",
    "def scene_change_detector_ml(frames, with_vis = False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ###\n",
    "    #  опишите здесь все функции, нужные для вашего решения\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        pass\n",
    "        # Основная часть вашего алгоритма\n",
    "        ###  END CODE HERE  ###\n",
    "    \n",
    "\n",
    "    model = pickle.load(open(\"model.pkl\", 'rb')) \n",
    "    predict_cuts = model.predict(X_test)\n",
    "    \n",
    "    return np.where(predict_cuts == 1)[0], vis, metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим ваше решение на всех видео.\n",
    "\n",
    "Не забывайте о том, что при итоговой оценке решений будет использоваться другой набор видео. Не переобучите модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scene_change_detector_all_video(scene_change_detector_ml, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Советы**\n",
    "\n",
    "* Используйте кросс-валидацию\n",
    "* Подумайте как лучше разделять видео на тренировочную и тестовые выборки\n",
    "* Подбирайте параметры модели (в библиотеке sklearn есть метод GridSearchCV для автоматического подбора параметров)\n",
    "* Пробуйте разные методы машинного обучения (из sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: детектор смен сцен типа наложение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично детектору из задания №1 за исключением того, что можно (и нужно) использовать машинное обучение:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector_dissolve_ml\n",
    "\n",
    "def scene_change_detector_dissolve_ml(frames, threshold=None, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        pass\n",
    "        # Основная часть вашего алгоритма\n",
    "        ###  END CODE HERE  ###\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'\n",
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video_dissolve(scene_change_detector_dissolve, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваши ощущения ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как и в первой части интересно узнать какие моменты показались простыми, а какие сложными. Много ли времени ушло на изучение sklearn и методов машинного обучения. Дало ли машинное обучение сразу прирост по сравнению с эврестической частью? Как вы контролировали переобучение?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
